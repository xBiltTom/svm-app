import streamlit as st
import pandas as pd
import numpy as np
from utils.data_processing import load_data, preprocess_data, split_data
from models.svm_classifier import train_svm, predict_svm, get_model_metrics, cross_validate_svm, perform_stratified_kfold
from utils.visualization import (
    plot_confusion_matrix, plot_decision_boundary, 
    plot_roc_curve, plot_roc_multiclass, 
    plot_cv_folds_comparison
)

st.set_page_config(
    page_title="SVM Classifier App",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ü§ñ M√°quinas de Vectores de Soporte (SVM)")
st.markdown("### Aplicaci√≥n interactiva para clasificaci√≥n con SVM")

# Sidebar para configuraci√≥n
st.sidebar.header("‚öôÔ∏è Configuraci√≥n del Modelo")

# Subida de archivo
uploaded_file = st.sidebar.file_uploader(
    "üìÅ Cargar dataset (CSV)",
    type=['csv'],
    help="Sube un archivo CSV con tus datos de clasificaci√≥n"
)

if uploaded_file is not None:
    # Cargar datos
    df = load_data(uploaded_file)
    
    st.sidebar.success(f"‚úÖ Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas")
    
    # Mostrar vista previa de los datos con scroll propio
    with st.expander("üìä Vista previa del dataset", expanded=False):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Filas", df.shape[0])
        with col2:
            st.metric("Columnas", df.shape[1])
        with col3:
            st.metric("Valores nulos", df.isnull().sum().sum())
        
        # DataFrame con scroll propio y altura fija
        st.dataframe(df, height=400, use_container_width=True)
    
    # Selecci√≥n de variables
    st.sidebar.subheader("üéØ Selecci√≥n de Variables")
    
    columns = df.columns.tolist()
    target_column = st.sidebar.selectbox(
        "Variable objetivo (target)",
        options=columns,
        index=len(columns)-1,
        help="Selecciona la columna que contiene las clases a predecir"
    )
    
    feature_columns = st.sidebar.multiselect(
        "Variables predictoras (features)",
        options=[col for col in columns if col != target_column],
        default=[col for col in columns if col != target_column][:min(4, len(columns)-1)],
        help="Selecciona las columnas que se usar√°n para entrenar el modelo"
    )
    
    if len(feature_columns) > 0:
        # Par√°metros del modelo SVM
        st.sidebar.markdown("---")
        st.sidebar.subheader("üîß Par√°metros del SVM")
        
        kernel = st.sidebar.selectbox(
            "Kernel",
            options=['linear', 'poly', 'rbf', 'sigmoid'],
            index=2,
            help="Funci√≥n kernel para el SVM"
        )
        
        C = st.sidebar.slider(
            "Par√°metro C (regularizaci√≥n)",
            min_value=0.01,
            max_value=100.0,
            value=1.0,
            step=0.01,
            help="Controla el trade-off entre error de entrenamiento y margen"
        )
        
        if kernel in ['rbf', 'poly', 'sigmoid']:
            gamma = st.sidebar.selectbox(
                "Gamma",
                options=['scale', 'auto'],
                index=0,
                help="Coeficiente del kernel"
            )
        else:
            gamma = 'scale'
        
        if kernel == 'poly':
            degree = st.sidebar.slider(
                "Grado del polinomio",
                min_value=2,
                max_value=5,
                value=3,
                help="Grado para el kernel polinomial"
            )
        else:
            degree = 3
        
        # Par√°metros de divisi√≥n de datos
        st.sidebar.markdown("---")
        st.sidebar.subheader("üìä Divisi√≥n de Datos")
        
        test_size = st.sidebar.slider(
            "Tama√±o del conjunto de prueba (%)",
            min_value=10,
            max_value=50,
            value=30,
            step=5,
            help="Porcentaje de datos para testing"
        ) / 100
        
        random_state = st.sidebar.number_input(
            "Semilla aleatoria",
            min_value=0,
            max_value=999,
            value=42,
            help="Para reproducibilidad de resultados"
        )
        
        # Bot√≥n de entrenamiento
        if st.sidebar.button("üöÄ Entrenar Modelo", type="primary", use_container_width=True):
            with st.spinner("Entrenando modelo SVM..."):
                try:
                    # Preparar datos
                    X, y, label_encoder = preprocess_data(df, feature_columns, target_column)
                    X_train, X_test, y_train, y_test = split_data(X, y, test_size, random_state)
                    
                    # Entrenamiento con par√°metros especificados
                    model, scaler = train_svm(
                        X_train, y_train,
                        kernel=kernel,
                        C=C,
                        gamma=gamma,
                        degree=degree,
                        random_state=random_state
                    )
                    
                    # Guardar en session state (datos SIN escalar para CV correcta)
                    st.session_state['model'] = model
                    st.session_state['scaler'] = scaler
                    st.session_state['X_train'] = X_train  # SIN escalar
                    st.session_state['X_test'] = X_test    # SIN escalar
                    st.session_state['y_train'] = y_train
                    st.session_state['y_test'] = y_test
                    st.session_state['label_encoder'] = label_encoder
                    st.session_state['feature_columns'] = feature_columns
                    st.session_state['target_column'] = target_column
                    st.session_state['random_state'] = random_state  # Guardar random_state
                    st.session_state['test_size'] = test_size  # Guardar test_size
                    # Guardar par√°metros del modelo
                    st.session_state['model_params'] = {
                        'kernel': kernel,
                        'C': C,
                        'gamma': gamma,
                        'degree': degree
                    }
                    
                    st.sidebar.success("‚úÖ Modelo entrenado exitosamente!")

                except Exception as e:
                    st.sidebar.error(f"‚ùå Error al entrenar el modelo: {str(e)}")
        
        # Mostrar resultados si el modelo est√° entrenado
        if 'model' in st.session_state:
            
            # Resultados del modelo entrenado
            st.markdown("---")
            st.header("üìà Resultados del Modelo Entrenado")
            
            model = st.session_state['model']
            scaler = st.session_state['scaler']
            X_train = st.session_state['X_train']
            X_test = st.session_state['X_test']
            y_train = st.session_state['y_train']
            y_test = st.session_state['y_test']
            label_encoder = st.session_state['label_encoder']
            
            # Predicciones
            y_train_pred = predict_svm(model, X_train, scaler)
            y_test_pred = predict_svm(model, X_test, scaler)
            
            # M√©tricas
            train_metrics = get_model_metrics(y_train, y_train_pred)
            test_metrics = get_model_metrics(y_test, y_test_pred)
            
            # Mostrar m√©tricas
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üìä M√©tricas de Entrenamiento")
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("Accuracy", f"{train_metrics['accuracy']:.3f}")
                with metric_col2:
                    st.metric("Precision", f"{train_metrics['precision']:.3f}")
                with metric_col3:
                    st.metric("Recall", f"{train_metrics['recall']:.3f}")
                
                st.metric("F1-Score", f"{train_metrics['f1']:.3f}")
            
            with col2:
                st.subheader("üìä M√©tricas de Prueba")
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("Accuracy", f"{test_metrics['accuracy']:.3f}")
                with metric_col2:
                    st.metric("Precision", f"{test_metrics['precision']:.3f}")
                with metric_col3:
                    st.metric("Recall", f"{test_metrics['recall']:.3f}")
                
                st.metric("F1-Score", f"{test_metrics['f1']:.3f}")
            
            st.markdown("---")
            
            # Visualizaciones
            st.header("üìâ Visualizaciones")
            
            tab1, tab2, tab3 = st.tabs(["Matriz de Confusi√≥n", "Frontera de Decisi√≥n", "Curva ROC"])
            
            with tab1:
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("Entrenamiento")
                    fig_cm_train = plot_confusion_matrix(
                        y_train, y_train_pred,
                        label_encoder.classes_,
                        "Matriz de Confusi√≥n - Entrenamiento"
                    )
                    st.pyplot(fig_cm_train)
                
                with col2:
                    st.subheader("Prueba")
                    fig_cm_test = plot_confusion_matrix(
                        y_test, y_test_pred,
                        label_encoder.classes_,
                        "Matriz de Confusi√≥n - Prueba"
                    )
                    st.pyplot(fig_cm_test)
            
            with tab2:
                if len(feature_columns) >= 2:
                    feature_x = st.selectbox("Feature X", feature_columns, index=0)
                    feature_y = st.selectbox("Feature Y", feature_columns, index=min(1, len(feature_columns)-1))
                    
                    idx_x = feature_columns.index(feature_x)
                    idx_y = feature_columns.index(feature_y)
                    
                    fig_boundary = plot_decision_boundary(
                        model, scaler, X_test, y_test,
                        idx_x, idx_y,
                        label_encoder.classes_,
                        feature_x, feature_y
                    )
                    st.pyplot(fig_boundary)
                else:
                    st.info("Se necesitan al menos 2 features para visualizar la frontera de decisi√≥n")
            
            
            with tab3:
                n_classes = len(np.unique(y_test))
                if n_classes == 2:
                    st.subheader("Clasificaci√≥n Binaria")
                    fig_roc = plot_roc_curve(model, X_test, y_test, scaler)
                    st.pyplot(fig_roc)
                    st.caption("La curva ROC muestra el balance entre tasa de verdaderos positivos y falsos positivos")
                else:
                    st.subheader("Clasificaci√≥n Multiclase")
                    fig_roc = plot_roc_multiclass(model, X_test, y_test, scaler, label_encoder.classes_)
                    st.pyplot(fig_roc)
                    st.caption("ROC para cada clase con promedios micro (global) y macro (por clase)")
            
            # Tabla de predicciones de prueba
            st.markdown("---")
            st.subheader("üìã Detalle de Predicciones del Conjunto de Prueba")
            
            # Crear DataFrame con predicciones
            feature_cols = st.session_state['feature_columns']
            predictions_df = pd.DataFrame(X_test, columns=feature_cols)
            predictions_df['Clase Real'] = label_encoder.inverse_transform(y_test)
            predictions_df['Clase Predicha'] = label_encoder.inverse_transform(y_test_pred)
            predictions_df['¬øCorrecto?'] = predictions_df['Clase Real'] == predictions_df['Clase Predicha']
            predictions_df['¬øCorrecto?'] = predictions_df['¬øCorrecto?'].map({True: '‚úÖ S√≠', False: '‚ùå No'})
            
            # Mostrar resumen
            total = len(predictions_df)
            correctos = (predictions_df['¬øCorrecto?'] == '‚úÖ S√≠').sum()
            incorrectos = total - correctos
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total de Muestras", total)
            with col2:
                st.metric("Clasificaciones Correctas", correctos, delta=f"{correctos/total*100:.1f}%")
            with col3:
                st.metric("Clasificaciones Incorrectas", incorrectos, delta=f"-{incorrectos/total*100:.1f}%" if incorrectos > 0 else "0%", delta_color="inverse")
            
            # Filtro para ver solo errores
            show_only_errors = st.checkbox("Mostrar solo clasificaciones incorrectas", value=False)
            
            if show_only_errors:
                display_df = predictions_df[predictions_df['¬øCorrecto?'] == '‚ùå No']
                if len(display_df) == 0:
                    st.success("üéâ ¬°No hay clasificaciones incorrectas!")
                else:
                    st.dataframe(display_df, height=300, use_container_width=True)
            else:
                st.dataframe(predictions_df, height=400, use_container_width=True)
            
            st.caption("Esta tabla muestra cada muestra del conjunto de prueba, su clasificaci√≥n real, la predicci√≥n del modelo y si acert√≥ o no.")
            
            # Informaci√≥n del modelo entrenado
            st.markdown("---")
            with st.expander("‚ÑπÔ∏è Informaci√≥n del Modelo Entrenado", expanded=False):
                model_params = st.session_state.get('model_params', {})
                random_state = st.session_state.get('random_state', 'N/A')
                test_size = st.session_state.get('test_size', 'N/A')
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("#### üìã Configuraci√≥n")
                    st.write(f"**Kernel:** {model_params.get('kernel', 'N/A')}")
                    st.write(f"**Par√°metro C:** {model_params.get('C', 'N/A')}")
                    gamma_val = model_params.get('gamma', 'N/A')
                    if model_params.get('kernel') in ['rbf', 'poly', 'sigmoid']:
                        st.write(f"**Gamma:** {gamma_val}")
                    if model_params.get('kernel') == 'poly':
                        st.write(f"**Grado (degree):** {model_params.get('degree', 'N/A')}")
                    st.write(f"**Random State:** {random_state}")
                    st.write(f"**Test Size:** {test_size*100:.0f}%" if isinstance(test_size, float) else f"**Test Size:** {test_size}")
                
                with col2:
                    st.markdown("#### üìä Estad√≠sticas")
                    st.write(f"**Vectores de soporte:** {model.n_support_.sum()}")
                    st.write(f"**Vectores por clase:** {list(model.n_support_)}")
                    st.write(f"**Clases:** {list(label_encoder.classes_)}")
                    st.write(f"**Features usadas:** {len(st.session_state['feature_columns'])}")
                    st.write(f"**Tama√±o entrenamiento:** {len(y_train)} muestras")
                    st.write(f"**Tama√±o prueba:** {len(y_test)} muestras")
            
            # NUEVA SECCI√ìN: Validaci√≥n Cruzada
            st.markdown("---")
            st.header("üîÑ Validaci√≥n Cruzada")
            
            # Validar que el modelo est√© entrenado antes de permitir CV
            if 'model' not in st.session_state or 'X_train' not in st.session_state:
                st.warning("‚ö†Ô∏è Debes entrenar un modelo primero antes de ejecutar la validaci√≥n cruzada.")
            else:
                with st.expander("‚ÑπÔ∏è Sobre la Validaci√≥n Cruzada", expanded=False):
                    st.markdown("""
                    **¬øQu√© es la Validaci√≥n Cruzada?**
                
                La validaci√≥n cruzada es una t√©cnica robusta para evaluar el rendimiento del modelo:
                
                - **Concepto**: Divide el dataset en K folds (particiones) y entrena K veces
                - **StratifiedKFold**: Mantiene la proporci√≥n de clases en cada fold
                - **Ventajas**:
                  - Uso eficiente de todos los datos
                  - Reduce el sesgo de una √∫nica partici√≥n
                  - Proporciona estimaciones m√°s confiables del rendimiento
                  - Detecta overfitting/underfitting
                
                **M√©tricas promediadas**: Obtenemos la media y desviaci√≥n est√°ndar de cada m√©trica
                """)
                
                cv_folds = st.slider(
                    "N√∫mero de folds para validaci√≥n cruzada",
                    min_value=2,
                    max_value=10,
                    value=5,
                    help="Mayor n√∫mero de folds = m√°s tiempo de c√≥mputo pero mejor estimaci√≥n"
                )
                
                if st.button("üîÑ Ejecutar Validaci√≥n Cruzada", type="secondary", use_container_width=True):
                    with st.spinner(f"Ejecutando validaci√≥n cruzada con {cv_folds} folds..."):
                        try:
                            # Obtener par√°metros del modelo guardados
                            model_params = st.session_state.get('model_params', {})
                            kernel = model_params.get('kernel', 'rbf')
                            C = model_params.get('C', 1.0)
                            gamma = model_params.get('gamma', 'scale')
                            degree = model_params.get('degree', 3)
                            random_state = st.session_state.get('random_state', 42)  # Usar el random_state guardado
                            
                            # Obtener todos los datos (sin split)
                            X_full = st.session_state['X_train']
                            y_full = st.session_state['y_train']
                            
                            # Combinar train y test para CV completa
                            X_full = np.vstack([st.session_state['X_train'], st.session_state['X_test']])
                            y_full = np.concatenate([st.session_state['y_train'], st.session_state['y_test']])
                            
                            # Ejecutar validaci√≥n cruzada
                            cv_results = cross_validate_svm(
                                X_full, y_full,
                                kernel=kernel,
                                C=C,
                                gamma=gamma,
                                degree=degree,
                                cv=cv_folds,
                                random_state=random_state
                            )
                            
                            # Ejecutar StratifiedKFold detallado
                            fold_results = perform_stratified_kfold(
                                X_full, y_full,
                                kernel=kernel,
                                C=C,
                                gamma=gamma,
                                degree=degree,
                                n_splits=cv_folds,
                                random_state=random_state
                            )
                            
                            st.session_state['cv_results'] = cv_results
                            st.session_state['fold_results'] = fold_results
                            
                            st.success("‚úÖ Validaci√≥n cruzada completada!")
                            
                        except Exception as e:
                            st.error(f"‚ùå Error en validaci√≥n cruzada: {str(e)}")
                
                # Mostrar resultados de CV si existen
                if 'cv_results' in st.session_state:
                    cv_results = st.session_state['cv_results']
                    fold_results = st.session_state['fold_results']
                    
                    st.subheader("üìä Resultados de Validaci√≥n Cruzada")
                    
                    # M√©tricas promedio
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric(
                            "Accuracy", 
                            f"{cv_results['accuracy']['mean']:.3f}",
                            delta=f"¬±{cv_results['accuracy']['std']:.3f}"
                        )
                    with col2:
                        st.metric(
                            "Precision", 
                            f"{cv_results['precision']['mean']:.3f}",
                            delta=f"¬±{cv_results['precision']['std']:.3f}"
                        )
                    with col3:
                        st.metric(
                            "Recall", 
                            f"{cv_results['recall']['mean']:.3f}",
                            delta=f"¬±{cv_results['recall']['std']:.3f}"
                        )
                    with col4:
                        st.metric(
                            "F1-Score", 
                            f"{cv_results['f1']['mean']:.3f}",
                            delta=f"¬±{cv_results['f1']['std']:.3f}"
                        )
                    
                    # Visualizaci√≥n de CV - Solo comparaci√≥n por fold
                    st.markdown("### üìà Comparaci√≥n por Fold")
                    fig_folds = plot_cv_folds_comparison(fold_results)
                    st.pyplot(fig_folds)
                    st.caption("Evoluci√≥n de m√©tricas por fold y resumen estad√≠stico")
                    
                    # Tabla detallada por fold
                    with st.expander("üìã Resultados Detallados por Fold"):
                        fold_df = pd.DataFrame([
                            {
                                'Fold': f['fold'],
                                'Tama√±o Train': f['train_size'],
                                'Tama√±o Val': f['val_size'],
                                'Accuracy': f'{f["metrics"]["accuracy"]:.4f}',
                                'Precision': f'{f["metrics"]["precision"]:.4f}',
                                'Recall': f'{f["metrics"]["recall"]:.4f}',
                                'F1-Score': f'{f["metrics"]["f1"]:.4f}'
                            }
                            for f in fold_results
                        ])
                        st.dataframe(fold_df, use_container_width=True)
                
    else:
        st.warning("‚ö†Ô∏è Por favor selecciona al menos una variable predictora")
        
else:
    st.info("üëà Comienza subiendo un archivo CSV desde el panel lateral")
    
    st.markdown("""
    ### üìö Sobre las M√°quinas de Vectores de Soporte (SVM)
    
    Las **SVM** son algoritmos de aprendizaje supervisado utilizados principalmente para **clasificaci√≥n**.
    
    #### üéØ Caracter√≠sticas principales:
    - Encuentran el hiperplano √≥ptimo que maximiza el margen entre clases
    - Funcionan bien en espacios de alta dimensionalidad
    - Efectivos cuando el n√∫mero de dimensiones es mayor que el n√∫mero de muestras
    - Utilizan diferentes funciones kernel para manejar datos no linealmente separables
    
    #### üîß Kernels disponibles:
    - **Linear:** Para datos linealmente separables
    - **RBF (Radial Basis Function):** El m√°s popular, funciona bien en la mayor√≠a de casos
    - **Polynomial:** Para relaciones polinomiales entre features
    - **Sigmoid:** Similar a redes neuronales
    
    #### üìä Formato del dataset:
    - Archivo CSV con encabezados
    - √öltima columna (o la que elijas) como variable objetivo
    - Valores num√©ricos o categ√≥ricos (se convertir√°n autom√°ticamente)
    """)
