import streamlit as st
import pandas as pd
import numpy as np
from utils.data_processing import load_data, preprocess_data, split_data
from models.svm_classifier import train_svm, predict_svm, get_model_metrics, cross_validate_svm, perform_stratified_kfold
from utils.visualization import (
    plot_confusion_matrix, plot_decision_boundary, plot_feature_importance, 
    plot_roc_curve, plot_roc_with_auc, plot_cv_results, 
    plot_cv_folds_comparison, plot_cv_scores_distribution
)

st.set_page_config(
    page_title="SVM Classifier App",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ü§ñ M√°quinas de Vectores de Soporte (SVM)")
st.markdown("### Aplicaci√≥n interactiva para clasificaci√≥n con SVM")

# Sidebar para configuraci√≥n
st.sidebar.header("‚öôÔ∏è Configuraci√≥n del Modelo")

# Subida de archivo
uploaded_file = st.sidebar.file_uploader(
    "üìÅ Cargar dataset (CSV)",
    type=['csv'],
    help="Sube un archivo CSV con tus datos de clasificaci√≥n"
)

if uploaded_file is not None:
    # Cargar datos
    df = load_data(uploaded_file)
    
    st.sidebar.success(f"‚úÖ Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas")
    
    # Mostrar vista previa de los datos
    with st.expander("üìä Vista previa del dataset", expanded=True):
        st.dataframe(df.head(10))
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Filas", df.shape[0])
        with col2:
            st.metric("Columnas", df.shape[1])
        with col3:
            st.metric("Valores nulos", df.isnull().sum().sum())
    
    # Selecci√≥n de variables
    st.sidebar.subheader("üéØ Selecci√≥n de Variables")
    
    columns = df.columns.tolist()
    target_column = st.sidebar.selectbox(
        "Variable objetivo (target)",
        options=columns,
        index=len(columns)-1,
        help="Selecciona la columna que contiene las clases a predecir"
    )
    
    feature_columns = st.sidebar.multiselect(
        "Variables predictoras (features)",
        options=[col for col in columns if col != target_column],
        default=[col for col in columns if col != target_column][:min(4, len(columns)-1)],
        help="Selecciona las columnas que se usar√°n para entrenar el modelo"
    )
    
    if len(feature_columns) > 0:
        # Par√°metros del modelo SVM
        st.sidebar.subheader("üîß Par√°metros del SVM")
        
        kernel = st.sidebar.selectbox(
            "Kernel",
            options=['linear', 'poly', 'rbf', 'sigmoid'],
            index=2,
            help="Funci√≥n kernel para el SVM"
        )
        
        C = st.sidebar.slider(
            "Par√°metro C (regularizaci√≥n)",
            min_value=0.01,
            max_value=100.0,
            value=1.0,
            step=0.01,
            help="Controla el trade-off entre error de entrenamiento y margen"
        )
        
        if kernel in ['rbf', 'poly', 'sigmoid']:
            gamma = st.sidebar.selectbox(
                "Gamma",
                options=['scale', 'auto'],
                index=0,
                help="Coeficiente del kernel"
            )
        else:
            gamma = 'scale'
        
        if kernel == 'poly':
            degree = st.sidebar.slider(
                "Grado del polinomio",
                min_value=2,
                max_value=5,
                value=3,
                help="Grado para el kernel polinomial"
            )
        else:
            degree = 3
        
        test_size = st.sidebar.slider(
            "Tama√±o del conjunto de prueba (%)",
            min_value=10,
            max_value=50,
            value=30,
            step=5,
            help="Porcentaje de datos para testing (70% entrenamiento / 30% prueba)"
        ) / 100
        
        random_state = st.sidebar.number_input(
            "Semilla aleatoria",
            min_value=0,
            max_value=999,
            value=42,
            help="Para reproducibilidad de resultados"
        )
        
        # Bot√≥n de entrenamiento
        if st.sidebar.button("üöÄ Entrenar Modelo", type="primary", use_container_width=True):
            with st.spinner("Entrenando modelo SVM..."):
                try:
                    # Preparar datos
                    X, y, label_encoder = preprocess_data(df, feature_columns, target_column)
                    X_train, X_test, y_train, y_test = split_data(X, y, test_size, random_state)
                    
                    # Entrenar modelo
                    model, scaler = train_svm(
                        X_train, y_train,
                        kernel=kernel,
                        C=C,
                        gamma=gamma,
                        degree=degree,
                        random_state=random_state
                    )
                    
                    # Guardar en session state
                    st.session_state['model'] = model
                    st.session_state['scaler'] = scaler
                    st.session_state['X_train'] = X_train
                    st.session_state['X_test'] = X_test
                    st.session_state['y_train'] = y_train
                    st.session_state['y_test'] = y_test
                    st.session_state['label_encoder'] = label_encoder
                    st.session_state['feature_columns'] = feature_columns
                    st.session_state['target_column'] = target_column
                    
                    st.sidebar.success("‚úÖ Modelo entrenado exitosamente!")
                    
                except Exception as e:
                    st.sidebar.error(f"‚ùå Error al entrenar el modelo: {str(e)}")
        
        # Mostrar resultados si el modelo est√° entrenado
        if 'model' in st.session_state:
            st.markdown("---")
            st.header("üìà Resultados del Modelo")
            
            model = st.session_state['model']
            scaler = st.session_state['scaler']
            X_train = st.session_state['X_train']
            X_test = st.session_state['X_test']
            y_train = st.session_state['y_train']
            y_test = st.session_state['y_test']
            label_encoder = st.session_state['label_encoder']
            
            # Predicciones
            y_train_pred = predict_svm(model, X_train, scaler)
            y_test_pred = predict_svm(model, X_test, scaler)
            
            # M√©tricas
            train_metrics = get_model_metrics(y_train, y_train_pred)
            test_metrics = get_model_metrics(y_test, y_test_pred)
            
            # Mostrar m√©tricas
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üìä M√©tricas de Entrenamiento")
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("Accuracy", f"{train_metrics['accuracy']:.3f}")
                with metric_col2:
                    st.metric("Precision", f"{train_metrics['precision']:.3f}")
                with metric_col3:
                    st.metric("Recall", f"{train_metrics['recall']:.3f}")
                
                st.metric("F1-Score", f"{train_metrics['f1']:.3f}")
            
            with col2:
                st.subheader("üìä M√©tricas de Prueba")
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("Accuracy", f"{test_metrics['accuracy']:.3f}")
                with metric_col2:
                    st.metric("Precision", f"{test_metrics['precision']:.3f}")
                with metric_col3:
                    st.metric("Recall", f"{test_metrics['recall']:.3f}")
                
                st.metric("F1-Score", f"{test_metrics['f1']:.3f}")
            
            st.markdown("---")
            
            # Visualizaciones
            st.header("üìâ Visualizaciones")
            
            tab1, tab2, tab3 = st.tabs(["Matriz de Confusi√≥n", "Frontera de Decisi√≥n", "Curva ROC"])
            
            with tab1:
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("Entrenamiento")
                    fig_cm_train = plot_confusion_matrix(
                        y_train, y_train_pred,
                        label_encoder.classes_,
                        "Matriz de Confusi√≥n - Entrenamiento"
                    )
                    st.pyplot(fig_cm_train)
                
                with col2:
                    st.subheader("Prueba")
                    fig_cm_test = plot_confusion_matrix(
                        y_test, y_test_pred,
                        label_encoder.classes_,
                        "Matriz de Confusi√≥n - Prueba"
                    )
                    st.pyplot(fig_cm_test)
            
            with tab2:
                if len(feature_columns) >= 2:
                    feature_x = st.selectbox("Feature X", feature_columns, index=0)
                    feature_y = st.selectbox("Feature Y", feature_columns, index=min(1, len(feature_columns)-1))
                    
                    idx_x = feature_columns.index(feature_x)
                    idx_y = feature_columns.index(feature_y)
                    
                    fig_boundary = plot_decision_boundary(
                        model, scaler, X_test, y_test,
                        idx_x, idx_y,
                        label_encoder.classes_,
                        feature_x, feature_y
                    )
                    st.pyplot(fig_boundary)
                else:
                    st.info("Se necesitan al menos 2 features para visualizar la frontera de decisi√≥n")
            
            
            with tab3:
                n_classes = len(np.unique(y_test))
                if n_classes == 2:
                    st.subheader("Clasificaci√≥n Binaria")
                    fig_roc = plot_roc_with_auc(model, X_test, y_test, scaler)
                    st.pyplot(fig_roc)
                else:
                    st.subheader("Clasificaci√≥n Multiclase")
                    fig_roc = plot_roc_with_auc(model, X_test, y_test, scaler, label_encoder.classes_)
                    st.pyplot(fig_roc)
            
            # NUEVA SECCI√ìN: Validaci√≥n Cruzada
            st.markdown("---")
            st.header("üîÑ Validaci√≥n Cruzada")
            
            with st.expander("‚ÑπÔ∏è Sobre la Validaci√≥n Cruzada", expanded=False):
                st.markdown("""
                **¬øQu√© es la Validaci√≥n Cruzada?**
                
                La validaci√≥n cruzada es una t√©cnica robusta para evaluar el rendimiento del modelo:
                
                - **Concepto**: Divide el dataset en K folds (particiones) y entrena K veces
                - **StratifiedKFold**: Mantiene la proporci√≥n de clases en cada fold
                - **Ventajas**:
                  - Uso eficiente de todos los datos
                  - Reduce el sesgo de una √∫nica partici√≥n
                  - Proporciona estimaciones m√°s confiables del rendimiento
                  - Detecta overfitting/underfitting
                
                **M√©tricas promediadas**: Obtenemos la media y desviaci√≥n est√°ndar de cada m√©trica
                """)
            
            cv_folds = st.slider(
                "N√∫mero de folds para validaci√≥n cruzada",
                min_value=2,
                max_value=10,
                value=5,
                help="Mayor n√∫mero de folds = m√°s tiempo de c√≥mputo pero mejor estimaci√≥n"
            )
            
            if st.button("üîÑ Ejecutar Validaci√≥n Cruzada", type="secondary", use_container_width=True):
                with st.spinner(f"Ejecutando validaci√≥n cruzada con {cv_folds} folds..."):
                    try:
                        # Obtener todos los datos (sin split)
                        X_full = st.session_state['X_train']
                        y_full = st.session_state['y_train']
                        
                        # Combinar train y test para CV completa
                        X_full = np.vstack([st.session_state['X_train'], st.session_state['X_test']])
                        y_full = np.concatenate([st.session_state['y_train'], st.session_state['y_test']])
                        
                        # Ejecutar validaci√≥n cruzada
                        cv_results = cross_validate_svm(
                            X_full, y_full,
                            kernel=kernel,
                            C=C,
                            gamma=gamma,
                            degree=degree,
                            cv=cv_folds,
                            random_state=random_state
                        )
                        
                        # Ejecutar StratifiedKFold detallado
                        fold_results = perform_stratified_kfold(
                            X_full, y_full,
                            kernel=kernel,
                            C=C,
                            gamma=gamma,
                            degree=degree,
                            n_splits=cv_folds,
                            random_state=random_state
                        )
                        
                        st.session_state['cv_results'] = cv_results
                        st.session_state['fold_results'] = fold_results
                        
                        st.success("‚úÖ Validaci√≥n cruzada completada!")
                        
                    except Exception as e:
                        st.error(f"‚ùå Error en validaci√≥n cruzada: {str(e)}")
            
            # Mostrar resultados de CV si existen
            if 'cv_results' in st.session_state:
                cv_results = st.session_state['cv_results']
                fold_results = st.session_state['fold_results']
                
                st.subheader("üìä Resultados de Validaci√≥n Cruzada")
                
                # M√©tricas promedio
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(
                        "Accuracy", 
                        f"{cv_results['accuracy']['mean']:.3f}",
                        delta=f"¬±{cv_results['accuracy']['std']:.3f}"
                    )
                with col2:
                    st.metric(
                        "Precision", 
                        f"{cv_results['precision']['mean']:.3f}",
                        delta=f"¬±{cv_results['precision']['std']:.3f}"
                    )
                with col3:
                    st.metric(
                        "Recall", 
                        f"{cv_results['recall']['mean']:.3f}",
                        delta=f"¬±{cv_results['recall']['std']:.3f}"
                    )
                with col4:
                    st.metric(
                        "F1-Score", 
                        f"{cv_results['f1']['mean']:.3f}",
                        delta=f"¬±{cv_results['f1']['std']:.3f}"
                    )
                
                # Visualizaciones de CV
                st.markdown("### üìà Visualizaciones de Validaci√≥n Cruzada")
                
                tab_cv1, tab_cv2, tab_cv3 = st.tabs([
                    "Promedios con Desviaci√≥n",
                    "Comparaci√≥n por Fold", 
                    "Distribuci√≥n de Scores"
                ])
                
                with tab_cv1:
                    fig_cv = plot_cv_results(cv_results)
                    st.pyplot(fig_cv)
                    st.caption("M√©tricas promedio con barras de error (desviaci√≥n est√°ndar)")
                
                with tab_cv2:
                    fig_folds = plot_cv_folds_comparison(fold_results)
                    st.pyplot(fig_folds)
                    st.caption("Comparaci√≥n de m√©tricas en cada fold individual")
                
                with tab_cv3:
                    fig_dist = plot_cv_scores_distribution(cv_results)
                    st.pyplot(fig_dist)
                    st.caption("Distribuci√≥n de scores usando boxplots (mediana=l√≠nea roja, media=diamante verde)")
                
                # Tabla detallada por fold
                with st.expander("üìã Resultados Detallados por Fold"):
                    fold_df = pd.DataFrame([
                        {
                            'Fold': f['fold'],
                            'Tama√±o Train': f['train_size'],
                            'Tama√±o Val': f['val_size'],
                            'Accuracy': f'{f["metrics"]["accuracy"]:.4f}',
                            'Precision': f'{f["metrics"]["precision"]:.4f}',
                            'Recall': f'{f["metrics"]["recall"]:.4f}',
                            'F1-Score': f'{f["metrics"]["f1"]:.4f}'
                        }
                        for f in fold_results
                    ])
                    st.dataframe(fold_df, use_container_width=True)
            
            # Informaci√≥n del modelo
            st.markdown("---")
            with st.expander("‚ÑπÔ∏è Informaci√≥n del Modelo"):
                st.write(f"**Kernel:** {kernel}")
                st.write(f"**C:** {C}")
                st.write(f"**Gamma:** {gamma}")
                if kernel == 'poly':
                    st.write(f"**Grado:** {degree}")
                st.write(f"**N√∫mero de vectores de soporte:** {model.n_support_.sum()}")
                st.write(f"**Clases:** {list(label_encoder.classes_)}")
                
    else:
        st.warning("‚ö†Ô∏è Por favor selecciona al menos una variable predictora")
        
else:
    st.info("üëà Comienza subiendo un archivo CSV desde el panel lateral")
    
    st.markdown("""
    ### üìö Sobre las M√°quinas de Vectores de Soporte (SVM)
    
    Las **SVM** son algoritmos de aprendizaje supervisado utilizados principalmente para **clasificaci√≥n**.
    
    #### üéØ Caracter√≠sticas principales:
    - Encuentran el hiperplano √≥ptimo que maximiza el margen entre clases
    - Funcionan bien en espacios de alta dimensionalidad
    - Efectivos cuando el n√∫mero de dimensiones es mayor que el n√∫mero de muestras
    - Utilizan diferentes funciones kernel para manejar datos no linealmente separables
    
    #### üîß Kernels disponibles:
    - **Linear:** Para datos linealmente separables
    - **RBF (Radial Basis Function):** El m√°s popular, funciona bien en la mayor√≠a de casos
    - **Polynomial:** Para relaciones polinomiales entre features
    - **Sigmoid:** Similar a redes neuronales
    
    #### üìä Formato del dataset:
    - Archivo CSV con encabezados
    - √öltima columna (o la que elijas) como variable objetivo
    - Valores num√©ricos o categ√≥ricos (se convertir√°n autom√°ticamente)
    """)
