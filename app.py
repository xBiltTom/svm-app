import streamlit as st
import pandas as pd
import numpy as np
from utils.data_processing import load_data, preprocess_data, split_data
from models.svm_classifier import train_svm, predict_svm, get_model_metrics, cross_validate_svm, perform_stratified_kfold
from utils.visualization import (
    plot_confusion_matrix, plot_decision_boundary, plot_feature_importance, 
    plot_roc_curve, plot_roc_with_auc, plot_cv_results, 
    plot_cv_folds_comparison, plot_cv_scores_distribution
)

st.set_page_config(
    page_title="SVM Classifier App",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ü§ñ M√°quinas de Vectores de Soporte (SVM)")
st.markdown("### Aplicaci√≥n interactiva para clasificaci√≥n con SVM")

# Sidebar para configuraci√≥n
st.sidebar.header("‚öôÔ∏è Configuraci√≥n del Modelo")

# Subida de archivo
uploaded_file = st.sidebar.file_uploader(
    "üìÅ Cargar dataset (CSV)",
    type=['csv'],
    help="Sube un archivo CSV con tus datos de clasificaci√≥n"
)

if uploaded_file is not None:
    # Cargar datos
    df = load_data(uploaded_file)
    
    st.sidebar.success(f"‚úÖ Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas")
    
    # Mostrar vista previa de los datos
    with st.expander("üìä Vista previa del dataset", expanded=True):
        st.dataframe(df.head(10))
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Filas", df.shape[0])
        with col2:
            st.metric("Columnas", df.shape[1])
        with col3:
            st.metric("Valores nulos", df.isnull().sum().sum())
    
    # Selecci√≥n de variables
    st.sidebar.subheader("üéØ Selecci√≥n de Variables")
    
    columns = df.columns.tolist()
    target_column = st.sidebar.selectbox(
        "Variable objetivo (target)",
        options=columns,
        index=len(columns)-1,
        help="Selecciona la columna que contiene las clases a predecir"
    )
    
    feature_columns = st.sidebar.multiselect(
        "Variables predictoras (features)",
        options=[col for col in columns if col != target_column],
        default=[col for col in columns if col != target_column][:min(4, len(columns)-1)],
        help="Selecciona las columnas que se usar√°n para entrenar el modelo"
    )
    
    if len(feature_columns) > 0:
        # Selector de modo de entrenamiento
        st.sidebar.markdown("---")
        st.sidebar.subheader("üéØ Modo de Entrenamiento")
        
        training_mode = st.sidebar.radio(
            "Seleccionar modo:",
            options=["Manual", "B√∫squeda Autom√°tica (Grid Search)"],
            index=0,
            help="Manual: Configuras los par√°metros manualmente\nB√∫squeda Autom√°tica: El sistema encuentra los mejores par√°metros"
        )
        
        if training_mode == "Manual":
            # Par√°metros del modelo SVM (configuraci√≥n manual)
            st.sidebar.subheader("üîß Par√°metros del SVM")
            
            kernel = st.sidebar.selectbox(
                "Kernel",
                options=['linear', 'poly', 'rbf', 'sigmoid'],
                index=2,
                help="Funci√≥n kernel para el SVM"
            )
            
            C = st.sidebar.slider(
                "Par√°metro C (regularizaci√≥n)",
                min_value=0.01,
                max_value=100.0,
                value=1.0,
                step=0.01,
                help="Controla el trade-off entre error de entrenamiento y margen"
            )
            
            if kernel in ['rbf', 'poly', 'sigmoid']:
                gamma = st.sidebar.selectbox(
                    "Gamma",
                    options=['scale', 'auto'],
                    index=0,
                    help="Coeficiente del kernel"
                )
            else:
                gamma = 'scale'
            
            if kernel == 'poly':
                degree = st.sidebar.slider(
                    "Grado del polinomio",
                    min_value=2,
                    max_value=5,
                    value=3,
                    help="Grado para el kernel polinomial"
                )
            else:
                degree = 3
        
        else:  # B√∫squeda Autom√°tica
            st.sidebar.subheader("üîç Configuraci√≥n de Grid Search")
            
            search_mode = st.sidebar.selectbox(
                "Modo de b√∫squeda",
                options=['quick', 'balanced', 'exhaustive'],
                index=1,
                format_func=lambda x: {
                    'quick': '‚ö° R√°pida (~50 combinaciones)',
                    'balanced': '‚öñÔ∏è Balanceada (~300 combinaciones)',
                    'exhaustive': 'üî¨ Exhaustiva (~1000+ combinaciones)'
                }[x],
                help="R√°pida: Prueba pocos par√°metros\nBalanceada: Equilibrio entre tiempo y cobertura\nExhaustiva: Prueba todas las combinaciones (puede tardar mucho)"
            )
            
            cv_folds_grid = st.sidebar.slider(
                "Folds para Cross-Validation",
                min_value=3,
                max_value=10,
                value=5,
                help="N√∫mero de particiones para validaci√≥n cruzada"
            )
        
        # Par√°metros comunes para ambos modos
        test_size = st.sidebar.slider(
            "Tama√±o del conjunto de prueba (%)",
            min_value=10,
            max_value=50,
            value=30,
            step=5,
            help="Porcentaje de datos para testing (70% entrenamiento / 30% prueba)"
        ) / 100
        
        random_state = st.sidebar.number_input(
            "Semilla aleatoria",
            min_value=0,
            max_value=999,
            value=42,
            help="Para reproducibilidad de resultados"
        )
        
        # Bot√≥n de entrenamiento
        if training_mode == "Manual":
            button_label = "üöÄ Entrenar Modelo"
        else:
            button_label = "üîç Buscar Mejores Par√°metros"
        
        if st.sidebar.button(button_label, type="primary", use_container_width=True):
            with st.spinner("Entrenando modelo SVM..." if training_mode == "Manual" else "Buscando mejores par√°metros..."):
                try:
                    # Preparar datos
                    X, y, label_encoder = preprocess_data(df, feature_columns, target_column)
                    X_train, X_test, y_train, y_test = split_data(X, y, test_size, random_state)
                    
                    if training_mode == "Manual":
                        # Entrenamiento manual con par√°metros especificados
                        model, scaler = train_svm(
                            X_train, y_train,
                            kernel=kernel,
                            C=C,
                            gamma=gamma,
                            degree=degree,
                            random_state=random_state
                        )
                        
                        # Guardar en session state (datos SIN escalar para CV correcta)
                        st.session_state['model'] = model
                        st.session_state['scaler'] = scaler
                        st.session_state['X_train'] = X_train  # SIN escalar
                        st.session_state['X_test'] = X_test    # SIN escalar
                        st.session_state['y_train'] = y_train
                        st.session_state['y_test'] = y_test
                        st.session_state['label_encoder'] = label_encoder
                        st.session_state['feature_columns'] = feature_columns
                        st.session_state['target_column'] = target_column
                        st.session_state['training_mode'] = 'manual'
                        # Guardar par√°metros del modelo
                        st.session_state['model_params'] = {
                            'kernel': kernel,
                            'C': C,
                            'gamma': gamma,
                            'degree': degree
                        }
                        
                        st.sidebar.success("‚úÖ Modelo entrenado exitosamente!")
                    
                    else:  # B√∫squeda Autom√°tica (Grid Search)
                        from models.svm_classifier import grid_search_svm, create_param_grid, get_grid_search_results_df
                        
                        # Crear grid de par√°metros seg√∫n modo seleccionado
                        param_grid = create_param_grid(search_mode)
                        
                        # Ejecutar Grid Search
                        grid_results = grid_search_svm(
                            X_train, y_train,
                            param_grid=param_grid,
                            cv=cv_folds_grid,
                            scoring='accuracy',
                            random_state=random_state
                        )
                        
                        # Extraer mejor modelo y scaler
                        model = grid_results['best_model']
                        scaler = grid_results['best_scaler']
                        
                        # Extraer par√°metros del mejor modelo
                        best_params = grid_results['best_params']
                        best_kernel = best_params.get('svm__kernel', 'rbf')
                        best_C = best_params.get('svm__C', 1.0)
                        best_gamma = best_params.get('svm__gamma', 'scale')
                        best_degree = best_params.get('svm__degree', 3)
                        
                        # Guardar en session state
                        st.session_state['model'] = model
                        st.session_state['scaler'] = scaler
                        st.session_state['X_train'] = X_train  # SIN escalar
                        st.session_state['X_test'] = X_test    # SIN escalar
                        st.session_state['y_train'] = y_train
                        st.session_state['y_test'] = y_test
                        st.session_state['label_encoder'] = label_encoder
                        st.session_state['feature_columns'] = feature_columns
                        st.session_state['target_column'] = target_column
                        st.session_state['training_mode'] = 'grid_search'
                        st.session_state['grid_results'] = grid_results
                        st.session_state['grid_results_df'] = get_grid_search_results_df(grid_results)
                        # Guardar par√°metros del mejor modelo
                        st.session_state['model_params'] = {
                            'kernel': best_kernel,
                            'C': best_C,
                            'gamma': best_gamma if best_kernel != 'linear' else None,
                            'degree': best_degree if best_kernel == 'poly' else None
                        }
                        
                        # Mostrar mejores par√°metros encontrados
                        st.sidebar.success(f"‚úÖ Mejor configuraci√≥n encontrada!")
                        st.sidebar.markdown(f"**Score CV:** {grid_results['best_score']:.4f}")
                        st.sidebar.markdown(f"**Kernel:** {best_kernel}")
                        st.sidebar.markdown(f"**C:** {best_C}")
                        
                        # Solo mostrar gamma si el kernel lo requiere
                        if best_kernel in ['rbf', 'poly', 'sigmoid']:
                            st.sidebar.markdown(f"**Gamma:** {best_gamma}")
                        
                        # Solo mostrar degree si es kernel poly
                        if best_kernel == 'poly':
                            st.sidebar.markdown(f"**Degree:** {best_degree}")
                        
                        st.sidebar.info(f"Se probaron {grid_results['n_combinations']} combinaciones")
                    

                except Exception as e:
                    st.sidebar.error(f"‚ùå Error al entrenar el modelo: {str(e)}")
        
        # Mostrar resultados si el modelo est√° entrenado
        if 'model' in st.session_state:
            
            # Si es Grid Search, mostrar vista simplificada
            if st.session_state.get('training_mode') == 'grid_search':
                st.markdown("---")
                st.header("üèÜ Configuraci√≥n √ìptima Encontrada")
                st.markdown("*Se probaron m√∫ltiples combinaciones de par√°metros mediante validaci√≥n cruzada*")
                
                model_params = st.session_state.get('model_params', {})
                grid_results = st.session_state['grid_results']
                
                # Obtener par√°metros
                best_kernel = model_params.get('kernel', 'N/A')
                best_C = model_params.get('C', 'N/A')
                best_gamma_raw = model_params.get('gamma', None)
                best_degree = model_params.get('degree', None)
                best_score = grid_results['best_score']
                n_combinations = grid_results['n_combinations']
                
                # Convertir gamma num√©rico a formato compatible con modo manual
                # Si gamma es un n√∫mero, mostrar advertencia de que no se puede usar directamente
                if best_gamma_raw is not None:
                    try:
                        gamma_float = float(best_gamma_raw)
                        # Es un valor num√©rico, no 'scale' o 'auto'
                        best_gamma = f"{gamma_float} (usar 'scale' en manual)"
                        gamma_is_numeric = True
                    except (ValueError, TypeError):
                        # Es 'scale' o 'auto'
                        best_gamma = best_gamma_raw
                        gamma_is_numeric = False
                else:
                    best_gamma = None
                    gamma_is_numeric = False
                
                # Crear contenido seg√∫n el kernel
                st.markdown("### üìã Par√°metros para ingresar en Modo Manual:")
                
                # Panel principal con la configuraci√≥n
                st.success(f"‚úÖ **Se probaron {n_combinations} combinaciones** y la mejor obtuvo **{best_score*100:.2f}% de precisi√≥n** en validaci√≥n cruzada.")
                
                # Mostrar configuraci√≥n de forma clara
                config_col1, config_col2 = st.columns(2)
                
                with config_col1:
                    st.markdown("#### üîß Configuraci√≥n del Kernel")
                    st.markdown(f"**1. Kernel:** `{best_kernel}`")
                    st.markdown(f"**2. Par√°metro C:** `{best_C}`")
                
                with config_col2:
                    st.markdown("#### ‚öôÔ∏è Par√°metros espec√≠ficos")
                    
                    if best_kernel == 'linear':
                        st.markdown("*El kernel linear no requiere par√°metros adicionales*")
                        st.markdown(f"- Gamma: No aplica")
                        st.markdown(f"- Degree: No aplica")
                    
                    elif best_kernel == 'rbf':
                        if best_gamma is not None:
                            st.markdown(f"**3. Gamma:** `{best_gamma}`")
                            if gamma_is_numeric:
                                st.warning("‚ö†Ô∏è El Grid Search encontr√≥ un valor num√©rico para gamma. En modo manual, usa 'scale' o 'auto'.")
                        st.markdown(f"- Degree: No aplica (solo para poly)")
                    
                    elif best_kernel == 'poly':
                        if best_gamma is not None:
                            st.markdown(f"**3. Gamma:** `{best_gamma}`")
                            if gamma_is_numeric:
                                st.warning("‚ö†Ô∏è El Grid Search encontr√≥ un valor num√©rico para gamma. En modo manual, usa 'scale' o 'auto'.")
                        if best_degree is not None:
                            st.markdown(f"**4. Degree:** `{best_degree}`")
                    
                    elif best_kernel == 'sigmoid':
                        if best_gamma is not None:
                            st.markdown(f"**3. Gamma:** `{best_gamma}`")
                            if gamma_is_numeric:
                                st.warning("‚ö†Ô∏è El Grid Search encontr√≥ un valor num√©rico para gamma. En modo manual, usa 'scale' o 'auto'.")
                        st.markdown(f"- Degree: No aplica (solo para poly)")
                
                # Resumen visual
                st.markdown("---")
                st.markdown("### üìù Resumen para copiar:")
                
                # Crear texto de resumen seg√∫n kernel
                if best_kernel == 'linear':
                    resumen = f"""
| Par√°metro | Valor |
|-----------|-------|
| **Kernel** | {best_kernel} |
| **C** | {best_C} |
"""
                elif best_kernel == 'rbf' or best_kernel == 'sigmoid':
                    # Mostrar gamma solo si no es None
                    gamma_display = best_gamma if best_gamma is not None else "N/A"
                    resumen = f"""
| Par√°metro | Valor |
|-----------|-------|
| **Kernel** | {best_kernel} |
| **C** | {best_C} |
| **Gamma** | {gamma_display} |
"""
                    if gamma_is_numeric:
                        resumen += "\n‚ö†Ô∏è **Nota:** El gamma es num√©rico. En modo manual, selecciona 'scale' o 'auto'.\n"
                
                elif best_kernel == 'poly':
                    gamma_display = best_gamma if best_gamma is not None else "N/A"
                    degree_display = best_degree if best_degree is not None else "N/A"
                    resumen = f"""
| Par√°metro | Valor |
|-----------|-------|
| **Kernel** | {best_kernel} |
| **C** | {best_C} |
| **Gamma** | {gamma_display} |
| **Degree** | {degree_display} |
"""
                    if gamma_is_numeric:
                        resumen += "\n‚ö†Ô∏è **Nota:** El gamma es num√©rico. En modo manual, selecciona 'scale' o 'auto'.\n"
                else:
                    resumen = f"""
| Par√°metro | Valor |
|-----------|-------|
| **Kernel** | {best_kernel} |
| **C** | {best_C} |
| **Gamma** | {best_gamma} |
| **Degree** | {best_degree} |
"""
                
                st.markdown(resumen)
                
                st.info(f"üí° **Siguiente paso:** Cambia a modo **Manual** en el panel lateral, ingresa estos par√°metros y entrena el modelo para verificar los resultados.")
            
            # Resultados del modelo entrenado (com√∫n para ambos modos)
            st.markdown("---")
            st.header("üìà Resultados del Modelo Entrenado")
            
            model = st.session_state['model']
            scaler = st.session_state['scaler']
            X_train = st.session_state['X_train']
            X_test = st.session_state['X_test']
            y_train = st.session_state['y_train']
            y_test = st.session_state['y_test']
            label_encoder = st.session_state['label_encoder']
            
            # Predicciones
            y_train_pred = predict_svm(model, X_train, scaler)
            y_test_pred = predict_svm(model, X_test, scaler)
            
            # M√©tricas
            train_metrics = get_model_metrics(y_train, y_train_pred)
            test_metrics = get_model_metrics(y_test, y_test_pred)
            
            # Mostrar m√©tricas
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üìä M√©tricas de Entrenamiento")
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("Accuracy", f"{train_metrics['accuracy']:.3f}")
                with metric_col2:
                    st.metric("Precision", f"{train_metrics['precision']:.3f}")
                with metric_col3:
                    st.metric("Recall", f"{train_metrics['recall']:.3f}")
                
                st.metric("F1-Score", f"{train_metrics['f1']:.3f}")
            
            with col2:
                st.subheader("üìä M√©tricas de Prueba")
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("Accuracy", f"{test_metrics['accuracy']:.3f}")
                with metric_col2:
                    st.metric("Precision", f"{test_metrics['precision']:.3f}")
                with metric_col3:
                    st.metric("Recall", f"{test_metrics['recall']:.3f}")
                
                st.metric("F1-Score", f"{test_metrics['f1']:.3f}")
            
            st.markdown("---")
            
            # Visualizaciones
            st.header("üìâ Visualizaciones")
            
            tab1, tab2, tab3 = st.tabs(["Matriz de Confusi√≥n", "Frontera de Decisi√≥n", "Curva ROC"])
            
            with tab1:
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("Entrenamiento")
                    fig_cm_train = plot_confusion_matrix(
                        y_train, y_train_pred,
                        label_encoder.classes_,
                        "Matriz de Confusi√≥n - Entrenamiento"
                    )
                    st.pyplot(fig_cm_train)
                
                with col2:
                    st.subheader("Prueba")
                    fig_cm_test = plot_confusion_matrix(
                        y_test, y_test_pred,
                        label_encoder.classes_,
                        "Matriz de Confusi√≥n - Prueba"
                    )
                    st.pyplot(fig_cm_test)
            
            with tab2:
                if len(feature_columns) >= 2:
                    feature_x = st.selectbox("Feature X", feature_columns, index=0)
                    feature_y = st.selectbox("Feature Y", feature_columns, index=min(1, len(feature_columns)-1))
                    
                    idx_x = feature_columns.index(feature_x)
                    idx_y = feature_columns.index(feature_y)
                    
                    fig_boundary = plot_decision_boundary(
                        model, scaler, X_test, y_test,
                        idx_x, idx_y,
                        label_encoder.classes_,
                        feature_x, feature_y
                    )
                    st.pyplot(fig_boundary)
                else:
                    st.info("Se necesitan al menos 2 features para visualizar la frontera de decisi√≥n")
            
            
            with tab3:
                n_classes = len(np.unique(y_test))
                if n_classes == 2:
                    st.subheader("Clasificaci√≥n Binaria")
                    fig_roc = plot_roc_with_auc(model, X_test, y_test, scaler)
                    st.pyplot(fig_roc)
                else:
                    st.subheader("Clasificaci√≥n Multiclase")
                    fig_roc = plot_roc_with_auc(model, X_test, y_test, scaler, label_encoder.classes_)
                    st.pyplot(fig_roc)
            
            # NUEVA SECCI√ìN: Validaci√≥n Cruzada
            st.markdown("---")
            st.header("üîÑ Validaci√≥n Cruzada")
            
            with st.expander("‚ÑπÔ∏è Sobre la Validaci√≥n Cruzada", expanded=False):
                st.markdown("""
                **¬øQu√© es la Validaci√≥n Cruzada?**
                
                La validaci√≥n cruzada es una t√©cnica robusta para evaluar el rendimiento del modelo:
                
                - **Concepto**: Divide el dataset en K folds (particiones) y entrena K veces
                - **StratifiedKFold**: Mantiene la proporci√≥n de clases en cada fold
                - **Ventajas**:
                  - Uso eficiente de todos los datos
                  - Reduce el sesgo de una √∫nica partici√≥n
                  - Proporciona estimaciones m√°s confiables del rendimiento
                  - Detecta overfitting/underfitting
                
                **M√©tricas promediadas**: Obtenemos la media y desviaci√≥n est√°ndar de cada m√©trica
                """)
            
            cv_folds = st.slider(
                "N√∫mero de folds para validaci√≥n cruzada",
                min_value=2,
                max_value=10,
                value=5,
                help="Mayor n√∫mero de folds = m√°s tiempo de c√≥mputo pero mejor estimaci√≥n"
            )
            
            if st.button("üîÑ Ejecutar Validaci√≥n Cruzada", type="secondary", use_container_width=True):
                with st.spinner(f"Ejecutando validaci√≥n cruzada con {cv_folds} folds..."):
                    try:
                        # Obtener par√°metros del modelo guardados
                        model_params = st.session_state.get('model_params', {})
                        kernel = model_params.get('kernel', 'rbf')
                        C = model_params.get('C', 1.0)
                        gamma = model_params.get('gamma', 'scale')
                        degree = model_params.get('degree', 3)
                        
                        # Obtener todos los datos (sin split)
                        X_full = st.session_state['X_train']
                        y_full = st.session_state['y_train']
                        
                        # Combinar train y test para CV completa
                        X_full = np.vstack([st.session_state['X_train'], st.session_state['X_test']])
                        y_full = np.concatenate([st.session_state['y_train'], st.session_state['y_test']])
                        
                        # Ejecutar validaci√≥n cruzada
                        cv_results = cross_validate_svm(
                            X_full, y_full,
                            kernel=kernel,
                            C=C,
                            gamma=gamma,
                            degree=degree,
                            cv=cv_folds,
                            random_state=random_state
                        )
                        
                        # Ejecutar StratifiedKFold detallado
                        fold_results = perform_stratified_kfold(
                            X_full, y_full,
                            kernel=kernel,
                            C=C,
                            gamma=gamma,
                            degree=degree,
                            n_splits=cv_folds,
                            random_state=random_state
                        )
                        
                        st.session_state['cv_results'] = cv_results
                        st.session_state['fold_results'] = fold_results
                        
                        st.success("‚úÖ Validaci√≥n cruzada completada!")
                        
                    except Exception as e:
                        st.error(f"‚ùå Error en validaci√≥n cruzada: {str(e)}")
            
            # Mostrar resultados de CV si existen
            if 'cv_results' in st.session_state:
                cv_results = st.session_state['cv_results']
                fold_results = st.session_state['fold_results']
                
                st.subheader("üìä Resultados de Validaci√≥n Cruzada")
                
                # M√©tricas promedio
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(
                        "Accuracy", 
                        f"{cv_results['accuracy']['mean']:.3f}",
                        delta=f"¬±{cv_results['accuracy']['std']:.3f}"
                    )
                with col2:
                    st.metric(
                        "Precision", 
                        f"{cv_results['precision']['mean']:.3f}",
                        delta=f"¬±{cv_results['precision']['std']:.3f}"
                    )
                with col3:
                    st.metric(
                        "Recall", 
                        f"{cv_results['recall']['mean']:.3f}",
                        delta=f"¬±{cv_results['recall']['std']:.3f}"
                    )
                with col4:
                    st.metric(
                        "F1-Score", 
                        f"{cv_results['f1']['mean']:.3f}",
                        delta=f"¬±{cv_results['f1']['std']:.3f}"
                    )
                
                # Visualizaciones de CV
                st.markdown("### üìà Visualizaciones de Validaci√≥n Cruzada")
                
                tab_cv1, tab_cv2, tab_cv3 = st.tabs([
                    "Promedios con Desviaci√≥n",
                    "Comparaci√≥n por Fold", 
                    "Distribuci√≥n de Scores"
                ])
                
                with tab_cv1:
                    fig_cv = plot_cv_results(cv_results)
                    st.pyplot(fig_cv)
                    st.caption("M√©tricas promedio con barras de error (desviaci√≥n est√°ndar)")
                
                with tab_cv2:
                    fig_folds = plot_cv_folds_comparison(fold_results)
                    st.pyplot(fig_folds)
                    st.caption("Comparaci√≥n de m√©tricas en cada fold individual")
                
                with tab_cv3:
                    fig_dist = plot_cv_scores_distribution(cv_results)
                    st.pyplot(fig_dist)
                    st.caption("Distribuci√≥n de scores usando boxplots (mediana=l√≠nea roja, media=diamante verde)")
                
                # Tabla detallada por fold
                with st.expander("üìã Resultados Detallados por Fold"):
                    fold_df = pd.DataFrame([
                        {
                            'Fold': f['fold'],
                            'Tama√±o Train': f['train_size'],
                            'Tama√±o Val': f['val_size'],
                            'Accuracy': f'{f["metrics"]["accuracy"]:.4f}',
                            'Precision': f'{f["metrics"]["precision"]:.4f}',
                            'Recall': f'{f["metrics"]["recall"]:.4f}',
                            'F1-Score': f'{f["metrics"]["f1"]:.4f}'
                        }
                        for f in fold_results
                    ])
                    st.dataframe(fold_df, use_container_width=True)
            
            # Informaci√≥n del modelo
            st.markdown("---")
            with st.expander("‚ÑπÔ∏è Informaci√≥n del Modelo"):
                model_params = st.session_state.get('model_params', {})
                kernel_info = model_params.get('kernel', 'N/A')
                C_info = model_params.get('C', 'N/A')
                gamma_info = model_params.get('gamma', 'N/A')
                degree_info = model_params.get('degree', 'N/A')
                
                st.write(f"**Kernel:** {kernel_info}")
                st.write(f"**C:** {C_info}")
                st.write(f"**Gamma:** {gamma_info}")
                if kernel_info == 'poly':
                    st.write(f"**Grado:** {degree_info}")
                st.write(f"**N√∫mero de vectores de soporte:** {model.n_support_.sum()}")
                st.write(f"**Clases:** {list(label_encoder.classes_)}")
                
    else:
        st.warning("‚ö†Ô∏è Por favor selecciona al menos una variable predictora")
        
else:
    st.info("üëà Comienza subiendo un archivo CSV desde el panel lateral")
    
    st.markdown("""
    ### üìö Sobre las M√°quinas de Vectores de Soporte (SVM)
    
    Las **SVM** son algoritmos de aprendizaje supervisado utilizados principalmente para **clasificaci√≥n**.
    
    #### üéØ Caracter√≠sticas principales:
    - Encuentran el hiperplano √≥ptimo que maximiza el margen entre clases
    - Funcionan bien en espacios de alta dimensionalidad
    - Efectivos cuando el n√∫mero de dimensiones es mayor que el n√∫mero de muestras
    - Utilizan diferentes funciones kernel para manejar datos no linealmente separables
    
    #### üîß Kernels disponibles:
    - **Linear:** Para datos linealmente separables
    - **RBF (Radial Basis Function):** El m√°s popular, funciona bien en la mayor√≠a de casos
    - **Polynomial:** Para relaciones polinomiales entre features
    - **Sigmoid:** Similar a redes neuronales
    
    #### üìä Formato del dataset:
    - Archivo CSV con encabezados
    - √öltima columna (o la que elijas) como variable objetivo
    - Valores num√©ricos o categ√≥ricos (se convertir√°n autom√°ticamente)
    """)
